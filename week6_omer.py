# -*- coding: utf-8 -*-
"""Week6_OMER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p6OZpqHGa2RrrxCfYPW0KzXyvokjALOO

##**Indian Cars: Data Processing & Visualization**
## By Syed Omer Ali [LinkedIn] (https://www.linkedin.com/in/syed-omer-ali-a5ab82256/)
Around 3.34 Lakh passenger datas were sold in the Indian market in May 2023. The sales increased by over 13% when compared to May last year. The Top 25 Selling Cars constituted over 75% of the cars sold in April 2023.

This dataset consists of 141 columns. Performing Exploratory Data analysis on this dataset. Document the findings and insights using proper graphs to represent the data.

We need to perform Univariate and Bivariate analysis for the given dataset. Below are the steps you can follow for both univariate and bivariate analysis of the dataset.

Note: This following notebooks deals with Data Processing
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px               # Plotly Express for interactive visualizations
import warnings

# Suppress SettingWithCopyWarning
warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)

# Setting display options for Pandas to show three decimal places for floating-point numbers
pd.set_option('display.float_format', lambda x: '%.3f' % x)

data = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/cars_ds_final.csv")

data

#check for missing values
data.isnull().sum().sum()

#understanding the number of rows and columns
data.shape

del data["Unnamed: 0"]

data.head(2)

data.dtypes

data.info(verbose=True)

data.shape

data.describe()

"""### 1. Handling large missing values




"""

# Calculate the percentage of missing values for each column in 'data' DataFrame
row_size = data.shape[0]
for i in data.columns:
    if data[i].isnull().sum() > 0:
        missing_percentage = (data[i].isnull().sum() / row_size) * 100
        print(i, "--------", missing_percentage)

#check for duplicate columns
data.duplicated().sum()

#delete duplicate columns
data = data.drop_duplicates()
data.duplicated().sum()

#observing current shape of the data
data.shape

"""In this step, we now remove columns from the 'car' DataFrame that have more than 70% missing values, excluding the 'ARAI_Certified_Mileage_for_CNG' column for future reference."""

# Remove columns with more than 70% missing values, excluding 'ARAI_Certified_Mileage_for_CNG'
row_size = data.shape[0]
for i in data.columns:
  if i!= 'ARAI_Certified_Mileage_for_CNG':
    if data[i].isna().sum() * 100 /row_size > 70:
      data.drop(columns=i, inplace=True)

data.shape

"""### 2. Processing Make, Model and Variant Datase

"""

# Fill missing values in 'Make' column with corresponding 'Model' values
data["Make"].fillna(data["Model"], inplace= True)

data["Make"].unique()

# Standardize 'Make' values in the 'car' DataFrame
data.loc[data["Make"].str.contains("Mercedes-Benz",na=False), "Make"] = "Mercedes-Benz" #na=False ensures that any NaN values in the "Make" column are treated as False rather than causing errors.
data.loc[data["Make"].str.contains("Rolls-Royce", na=False), "Make"] = "Rolls-Royce"
data.loc[data["Make"].str.contains("Maruti Suzuki R", na= False), "Make"] = "Maruti Suzuki"
data.loc[data['Make'].str.contains('Go+', na=False), 'Make'] = 'Datsun'
data["Make"] = data["Make"].str.replace('Land Rover Rover', 'Land Rover')

data["Make"].unique()

data.sample(5)

# Update 'Make', 'Model', and 'Variant' values in the 'car' DataFrame
data.loc[data['Make'].str.contains('Wagon', na=False), 'Make'] = 'Wagon R'
data['Model'] = data['Model'].str.replace('Wagon', 'Wagon R')
data['Model'] = data['Model'].str.replace('Mercedes-Benz ', '')
data['Model'] = data['Model'].str.replace('Rolls-Royce ', '')
data['Variant'] = data['Variant'].str.replace('Datsun ', '')

data.sample(5)

"""### 3. Processing Ex-Showroom_Price and Displacement Dataset"""

# Display specific columns 'Ex-Showroom_Price' and 'Displacement' from the 'car' DataFrame
specific_1 = ['Ex-Showroom_Price','Displacement']
print(data[specific_1].head(5))

""" clean the 'Ex-Showroom_Price' column by removing non-numeric characters, rename it to 'Ex-Showroom_Price_INR', and convert the values to integers in the 'car' DataFrame."""

# Clean 'Displacement' column in 'car' DataFrame
data['Ex-Showroom_Price'] = data['Ex-Showroom_Price'].replace(r"\D","",regex=True)
# Rename the cleaned column to 'Ex-Showroom_Price_INR'
data.rename(columns={'Ex-Showroom_Price':'Ex-Showroom_Price_INR'}, inplace=True)
# Convert 'Ex-Showroom_Price_INR' column to integer type
data['Ex-Showroom_Price_INR'] = data['Ex-Showroom_Price_INR'].astype(int)

"""code cleans the 'Displacement' column by removing non-numeric characters, renames it to 'Displacement_cc', and converts the values to float in the 'car' DataFrame"""

#cleaning of the displacement column
data['Displacement'] = data['Displacement'].replace(r'\D', "", regex=True)
#Renaming the displacement column
data.rename(columns={'Displacement': "Displacement_cc"},inplace=True)
#Convert the values to float
data["Displacement_cc"] = data["Displacement_cc"].astype(float)

# Display specific columns 'Ex-Showroom_Price_INR' and 'Displacement_cc' from the 'car' DataFrame
specific_1 = ['Ex-Showroom_Price_INR', 'Displacement_cc']
print(data[specific_1].head())

"""### 4. Ensuring Datatypes of Cylinders and Valves_Per_Cylinder Dataset"""

data['Cylinders'] = data['Cylinders'].astype(float)               # Convert 'Cylinders' column to float type in 'car' DataFrame

data['Valves_Per_Cylinder'] = data['Valves_Per_Cylinder'].astype(float)       # Convert 'Valves_Per_Cylinder' column to float type in 'car' DataFrame

"""### 5. Processing Drivetrain Datase"""

data["Drivetrain"].unique()

data["Drivetrain"] = data["Drivetrain"].str.replace(r'\(Rear Wheel Drive\)', "", regex = True)
data['Drivetrain'] = data['Drivetrain'].str.replace(r'\(Front Wheel Drive\)', '', regex=True)
data['Drivetrain'] = data['Drivetrain'].str.replace(r'\(All Wheel Drive\)', '', regex=True)

data["Drivetrain"].unique()

"""### 6. Processing Emission_Norm and Engine_Location Dataset

we observe the unique values in the 'Emission_Norm' column of the 'car' DataFrame to understand the different emission norms present in the dataset.
"""

data['Emission_Norm'].unique()

data['Emission_Norm'] = data['Emission_Norm'].str.replace('BS 6',"BS VI")

data['Emission_Norm'].unique()

"""Here, we explore the unique values in the 'Engine_Location' column of the 'car' DataFrame to understand the various engine locations recorded in the dataset."""

data["Engine_Location"] = data["Engine_Location"].str.replace(", ","-")

data["Engine_Location"].unique()

"""### 7. Processing Fuel_Tank_Capacity, Height, Length, Width, Kerb_Weight and Ground_Clearance Dataset"""

# Display the 'Fuel_Tank_Capacity' column from the 'car' DataFrame
data["Fuel_Tank_Capacity"].head()

"""This code cleans the 'Fuel_Tank_Capacity' column by removing non-numeric characters, renames it to 'Fuel_Tank_Capacity_litres', and converts the values to float in the 'car' DataFrame."""

data["Fuel_Tank_Capacity"] = data["Fuel_Tank_Capacity"].replace(r'\D',"",regex=True)
data.rename(columns={'Fuel_Tank_Capacity':'Fuel_Tank_Capacity_litres'},inplace=True)
data['Fuel_Tank_Capacity_litres'] = data['Fuel_Tank_Capacity_litres'].astype(float)

data["Fuel_Tank_Capacity_litres"].head()

"""Here, we print the first few rows of selected dimensions ('Height', 'Length', 'Width', 'Kerb_Weight', 'Ground_Clearance') from the 'car' DataFrame for inspection."""

dimensions = ['Height', 'Length', 'Width', 'Kerb_Weight', 'Ground_Clearance']
print(data[dimensions].head())

"""This code cleans and standardizes various dimensions columns in the 'car' DataFrame, renaming columns to reflect units and converting them to float type for consistency."""

# Clean and standardize dimensions in 'car' DataFrame
data['Height'] = data['Height'].str.replace(r'\D', "" , regex=True)
data['Length'] = data['Length'].str.replace(r'\D', "" , regex=True)
data['Width'] = data['Width'].str.replace(r'\D', "" , regex=True)
data['Kerb_Weight'] = data['Kerb_Weight'].replace(r'\D', '', regex=True)
data['Ground_Clearance'] = data['Ground_Clearance'].replace(r'\D', '', regex=True)

#renaming
data.rename(columns={'Height': 'Height_mm','Length': 'Length_mm','Width': 'Width_mm','Kerb_Weight': 'Kerb_Weight_kg','Ground_Clearance':'Ground_Clearance_mm'},inplace=True)

# Convert cleaned columns to float type
data['Height_mm'] = data['Height_mm'].astype(float)
data['Length_mm'] = data['Length_mm'].astype(float)
data['Width_mm'] = data['Width_mm'].astype(float)
data['Kerb_Weight_kg'] = data['Kerb_Weight_kg'].astype(float)
data['Ground_Clearance_mm'] = data['Ground_Clearance_mm'].astype(float)

#display the changes
dimension = ['Height_mm', 'Length_mm', 'Width_mm', 'Kerb_Weight_kg', 'Ground_Clearance_mm']
data[dimension].head()

"""### 8. Processing Body_Type, Gears, and Body_Type Dataset"""

data["Body_Type"].unique()               # Display unique values in the 'Body_Type' column of the 'car' DataFrame

# Display the count of each unique value in the 'Gears' column of the 'car' DataFrame
data["Gears"].value_counts()

"""This code updates and converts the 'Gears' column in the 'car' DataFrame, replacing specific values and converting the column to float type.
The count of each unique value in the updated 'Gears' column is then displayed.
"""

data["Gears"] = data["Gears"].replace({'Single Speed Reduction Gear':'1','7 Dual Clutch':7})
data["Gears"] = data["Gears"].astype(float)
#count of each unique value
data["Gears"].value_counts()

"""This code modifies the 'Body_Type' column in the 'car' DataFrame by replacing ', ' with '-' for consistency and clarity."""

data["Body_Type"] = data["Body_Type"].str.replace(",","-")

data["Body_Type"].unique()

"""### 9. Processing Mileage Datasets"""

#count the number of missing values in the 'ARAI_Certified_Mileage' column of the 'car' DataFrame
data["ARAI_Certified_Mileage"].isna().sum()

# Fill missing values in 'ARAI_Certified_Mileage' with 'Highway_Mileage' for non-CNG vehicles in 'car' DataFrame
data.loc[data['Fuel_Type']!= 'CNG' ,'ARAI_Certified_Mileage' ] = data['ARAI_Certified_Mileage'].fillna(data['Highway_Mileage'])

# Re-check the number of missing values in the 'ARAI_Certified_Mileage' column of the 'car' DataFrame
data["ARAI_Certified_Mileage"].isna().sum()

data['ARAI_Certified_Mileage'].unique()              # Display unique values in the 'ARAI_Certified_Mileage' column of the 'car' DataFrame

"""This code cleans and standardizes the 'ARAI_Certified_Mileage' column in the 'car' DataFrame, addressing units and replacing specific incorrect values.
The cleaned column is then renamed to 'ARAI_Certified_Mileage_kmpl'.
"""

#cleans and standardizes the 'ARAI_Certified_Mileage' column
data['ARAI_Certified_Mileage'] = data['ARAI_Certified_Mileage'].replace(r'\s*km/litre',"",regex=True)
data['ARAI_Certified_Mileage'] = data['ARAI_Certified_Mileage'].replace('9.8-10.0',"10")
data['ARAI_Certified_Mileage'] = data['ARAI_Certified_Mileage'].replace('22.4-21.9',"22.4")
data['ARAI_Certified_Mileage'] = data['ARAI_Certified_Mileage'].replace(r'\s*kmpl',"",regex=True)

#convert the datatype
data['ARAI_Certified_Mileage'] = data['ARAI_Certified_Mileage'].astype(float)

#replacing inconsistencies
data['ARAI_Certified_Mileage'] = data['ARAI_Certified_Mileage'].replace('22.4-21.9',"22.4")

# Replace specific incorrect values
data['ARAI_Certified_Mileage'] = data['ARAI_Certified_Mileage'].replace(142.0, 14.2)
data['ARAI_Certified_Mileage'] = data['ARAI_Certified_Mileage'].replace(1449.0, 14.49)

# Rename the cleaned column to 'ARAI_Certified_Mileage_kmpl'
data.rename(columns={'ARAI_Certified_Mileage': 'ARAI_Certified_Mileage_kmpl'}, inplace=True)

data['ARAI_Certified_Mileage_kmpl'].unique()

"""
Here, we inspect the unique values in the 'ARAI_Certified_Mileage_for_CNG' column of the 'car' DataFrame to understand the ARAI certified mileage values for CNG-powered vehicles."""

data['ARAI_Certified_Mileage_for_CNG'].unique()

"""This code cleans and standardizes the 'ARAI_Certified_Mileage_for_CNG' column in the 'car' DataFrame, addressing units. The cleaned column is then renamed to 'ARAI_Certified_Mileage_for_CNG_kmpkg'."""

#cleaning the data
data['ARAI_Certified_Mileage_for_CNG'] = data['ARAI_Certified_Mileage_for_CNG'].replace(r'\s*km/kg',"",regex=True)
#convert data type
data['ARAI_Certified_Mileage_for_CNG'].astype(float)
#renaming the data frame
data.rename(columns={'ARAI_Certified_Mileage_for_CNG':'ARAI_Certified_Mileage_for_CNG_kmpkg'},inplace=True)

data['ARAI_Certified_Mileage_for_CNG_kmpkg'].unique()

"""This line of code fills missing values in the 'ARAI_Certified_Mileage_kmpl' column with values from the corresponding 'ARAI_Certified_Mileage_for_CNG_kmpkg' column in the 'car' DataFrame."""

data['ARAI_Certified_Mileage_kmpl'].fillna(data['ARAI_Certified_Mileage_for_CNG_kmpkg'],inplace=True)

# Drop columns 'City_Mileage' and 'Highway_Mileage' from 'car' DataFrame
data.drop(columns={'City_Mileage', 'Highway_Mileage','ARAI_Certified_Mileage_for_CNG_kmpkg'},inplace=True)

"""### 10. Processing Suspension Datasets

"""

data['Front_Suspension'].unique()

# Update 'Front_Suspension' column in 'car' DataFrame with standardized suspension types
data.loc[data['Front_Suspension'].str.contains('MacPherson|Mac Pherson|Mc Pherson|McPherson|Macpherson|Mcpherson', na=False), 'Front_Suspension'] = 'MacPherson Suspension'
data.loc[data['Front_Suspension'].str.contains('Double Wishbone|Double wishbone|double-wishbone|double wishbone|Double wish-bone', na=False), 'Front_Suspension'] = 'Double Wishbone Suspension'
data.loc[data['Front_Suspension'].str.contains('link|Link', na=False), 'Front_Suspension'] = 'Multi Link Suspension'
data.loc[data['Front_Suspension'].str.contains('Adaptive|adaptive', na=False), 'Front_Suspension'] = 'Adaptive Suspension'
data.loc[data['Front_Suspension'].str.contains('Leaf spring|leaf spring|Leaf Spring', na=False), 'Front_Suspension'] = 'Leaf Spring Suspension'
data.loc[data['Front_Suspension'].str.contains('Air|air|AIRMATIC', na=False), 'Front_Suspension'] = 'Air Suspension'
data.loc[data['Front_Suspension'].str.contains('Damper|damper|damping|CONTROL', na=False), 'Front_Suspension'] = 'Damper Suspension'
data.loc[data['Front_Suspension'].str.contains('Independent|independent', na=False), 'Front_Suspension'] = 'Independent Suspension'
data.loc[data['Front_Suspension'].str.contains('Double joint|Double-Joint', na=False), 'Front_Suspension'] = 'Double Joint Suspension'
data.loc[data['Front_Suspension'].str.contains('single joint ', na=False), 'Front_Suspension'] = 'Single Joint Suspension'
data.loc[~data['Front_Suspension'].str.contains('MacPherson|Double Wishbone|Multi Link|Adaptive|Leaf Spring|Air|Damper|Independent|Double', na=False), 'Front_Suspension'] = 'Aluminium Suspension'

# Display unique values in the updated 'Front_Suspension' column of the 'car' DataFrame
data['Front_Suspension'].unique()

"""Here, we inspect the unique values in the 'Rear_Suspension' column of the 'car' DataFrame to understand the different rear suspension configurations recorded in the dataset."""

data['Rear_Suspension'].unique()

# Update 'Rear_Suspension' column in 'data' DataFrame with standardized suspension types
data.loc[data['Rear_Suspension'].str.contains('multi-link|multilink', case=False, na=False), 'Rear_Suspension'] = 'Multi-link Suspension'
data.loc[data['Rear_Suspension'].str.contains('torsion beam|torsion bar', case=False, na=False), 'Rear_Suspension'] = 'Torsion Beam Suspension'
data.loc[data['Rear_Suspension'].str.contains('double wishbone|wishbone', case=False, na=False), 'Rear_Suspension'] = 'Double Wishbone Suspension'
data.loc[data['Rear_Suspension'].str.contains('coil spring|coil-over|coilover', case=False, na=False), 'Rear_Suspension'] = 'Coil Spring Suspension'
data.loc[data['Rear_Suspension'].str.contains('independent|macpherson|mcpherson', case=False, na=False), 'Rear_Suspension'] = 'Independent Suspension'
data.loc[data['Rear_Suspension'].str.contains('leaf spring|leaf-sprung|leafsprung', case=False, na=False), 'Rear_Suspension'] = 'Leaf Spring Suspension'
data.loc[~data['Rear_Suspension'].str.contains('Multi-link|Torsion Beam|Double Wishbone|Coil Spring|Independent|Leaf Spring', case=False, na=False), 'Rear_Suspension'] = 'Other Suspension'

# Display unique values in the updated 'Rear_Suspension' column of the 'car' DataFrame
data['Rear_Suspension'].unique()



"""### 11. Processing Track Datasets"""

data[['Front_Track', 'Rear_Track']].head()

"""This code cleans and standardizes the 'Front_Track' and 'Rear_Track' columns in the 'car' DataFrame, renaming columns to reflect units and converting them to float type for consistency."""

# Clean and standardize 'Front_Track' and 'Rear_Track' columns in 'car' DataFrame
data['Front_Track'] = data['Front_Track'].replace(r'\D', '', regex=True)
data['Rear_Track'] = data['Rear_Track'].replace(r'\D', '', regex=True)

# Rename columns to reflect units and data type
data.rename(columns={'Front_Track': 'Front_Track_mm','Rear_Track': 'Rear_Track_mm'}, inplace=True)

# Convert cleaned columns to float type
data['Front_Track_mm'] = data['Front_Track_mm'].astype(float)
data['Rear_Track_mm'] = data['Rear_Track_mm'].astype(float)

data[['Front_Track_mm','Rear_Track_mm']].head()

"""### 12. Processing Tire Datasets"""

# Remove spaces from the 'Front_Tyre_&_Rim' column in 'car' DataFrame and display unique values
data['Front_Tyre_&_Rim'] = data['Front_Tyre_&_Rim'].str.replace(' ','',regex=False)
data['Front_Tyre_&_Rim'].unique()

"""This code splits and extracts information from the 'Front_Tyre_&_Rim' column, then cleans and replaces specific values in the relevant columns ('F_Tire_Width', 'F_Tire_Aspect_Ratio', 'F_Tire_Diameter'). The cleaned columns are converted to float type for consistency"""

# Split and extract information from 'Front_Tyre_&_Rim' column, and clean relevant columns
data[['F_Tire_Width','F_Tire']] = data['Front_Tyre_&_Rim'].str.split('/',n=1,expand=True)
data[['F_Tire_Aspect_Ratio','F_Tire_Diameter']] = data["F_Tire"].str.split('R',n=1,expand=True)
# Drop the original 'F_Tire' column
data.drop(columns="F_Tire",inplace=True)
# Clean and replace specific values in the extracted columns
data['F_Tire_Width'] = data['F_Tire_Width'].replace({'155R13LT':'155','(245':'245','R12':np.nan,'R16':np.nan,'43.66cm':np.nan,'P215':'215','P235':'235','145R12LT6PR':'145' , '195R15LT,8PRRadial':'195','21565R16':'215'})
data['F_Tire_Aspect_Ratio'] = data['F_Tire_Aspect_Ratio'].replace({'17"LightAlloyWheelsJCWTrackSpoke,Black':'43','35Z':'35','Z':'','40/20':'40','30Z':'30','40Z':'40','60/':'60','45Z':'45','60Z':'60','60V':'60','55Z':'55','155':np.nan,None:np.nan})
data['F_Tire_Diameter'] = data['F_Tire_Diameter'].replace({'15Steel':'15','18TubelessRadials':'18','F20':'20','1794Y':np.nan,None:np.nan})
# Convert the cleaned columns to float type
data['F_Tire_Width'] = data['F_Tire_Width'].astype(float)
data['F_Tire_Aspect_Ratio'] = data['F_Tire_Aspect_Ratio'].astype(float)
data['F_Tire_Diameter'] = data['F_Tire_Diameter'].astype(float)

"""Now we explore unique values for the cleaned data"""

data["F_Tire_Width"].unique()

data['F_Tire_Aspect_Ratio'].unique()

data['F_Tire_Diameter'].unique()

"""This code reorders and renames columns in the 'car' DataFrame, placing 'F_Tire_Width', 'F_Tire_Aspect_Ratio', and 'F_Tire_Diameter' in front for better organization. The original 'Front_Tyre_&_Rim' column is dropped."""

# Reorder and rename columns in 'car' DataFrame for better organization
width = data.columns.get_loc("F_Tire_Width")
aspect = data.columns.get_loc("F_Tire_Aspect_Ratio")
diameter = data.columns.get_loc('F_Tire_Diameter')
front = data.columns.get_loc("Front_Tyre_&_Rim")

# Move the columns to the desired positions
columns_to_move = data.pop("F_Tire_Width")
data.insert(front,"F_Tire_Width",columns_to_move)

columns_to_move = data.pop("F_Tire_Aspect_Ratio")
data.insert(front,'F_Tire_Aspect_Ratio',columns_to_move)

columns_to_move = data.pop("F_Tire_Diameter")
data.insert(front,'F_Tire_Diameter',columns_to_move)

# Drop the original 'Front_Tyre_&_Rim' column and rename the reordered columns
data.drop(columns=["Front_Tyre_&_Rim"],inplace=True)

data.rename(columns={"F_Tire_Width":"F_Tire_Width_mm",'F_Tire_Diameter': 'F_Tire_Diameter_inch'},inplace=True)

"""This code removes spaces from the 'Rear_Tyre_&_Rim' column in the 'car' DataFrame and displays unique values, ensuring consistent formatting."""

data['Rear_Tyre_&_Rim'].unique()

#removing inconsistencies
data['Rear_Tyre_&_Rim'] = data['Rear_Tyre_&_Rim'].str.replace(" ","")
data['Rear_Tyre_&_Rim'].unique()

"""This code splits and extracts information from the 'Rear_Tyre_&_Rim' column, then cleans and replaces specific values in the relevant columns ('R_Tire_Width', 'R_Tire_Aspect_Ratio', 'R_Tire_Diameter'). The cleaned columns are converted to float type for consistency."""

# Split and extract information from 'Rear_Tyre_&_Rim' column, and clean relevant columns
data[['R_Tire_Width', 'R_Tyre']] = data['Rear_Tyre_&_Rim'].str.split("/",n=1,expand=True)
data[['R_Tire_Aspect_Ratio', 'R_Tire_Diameter']] = data['R_Tyre'].str.split("R",n=1,expand=True)

#drop R_Tyre colunmn
data.drop(columns=["R_Tyre"],inplace=True)
# Clean and replace specific values in the extracted columns
data['R_Tire_Width'] = data['R_Tire_Width'].replace({'155R13LT':'155', '(245':'245', 'R12':np.nan, 'R16':np.nan, '43.66cm':np.nan, 'P215':'215', 'P235':'235', '145R12LT6PR':'145', '195R15LT,8PRRadial':'195', '21565R16':'215'})
data['R_Tire_Aspect_Ratio'] = data['R_Tire_Aspect_Ratio'].replace({'17"LightAlloyWheelsJCWTrackSpoke,Black':'43', '35/20':'35', '25Z':'25', '50Z':'50', '335':np.nan, '60/':'60', '30Z':'30', '60Z':'60', '40Z':'40', '60V':'60', '35Z':'35', '155':np.nan, None:np.nan})
data['R_Tire_Diameter'] = data['R_Tire_Diameter'].replace({None:np.nan, '1794Y':np.nan, '15Steel':'15', '18TubelessRadials':'18', 'F20':'20'})

# Convert the cleaned columns to float type
data['R_Tire_Width'] = data['R_Tire_Width'].astype(float)
data['R_Tire_Aspect_Ratio'] = data['R_Tire_Aspect_Ratio'].astype(float)
data['R_Tire_Diameter'] = data['R_Tire_Diameter'].astype(float)

"""Now, we explore the unique values in the cleaned 'R_Tire_Width' column of the 'car' DataFrame after the data cleaning and standardization process."""

data['R_Tire_Width'].unique()

data['R_Tire_Aspect_Ratio'].unique()

data['R_Tire_Diameter'].unique()

"""This code reorders and renames columns in the 'car' DataFrame, placing 'R_Tire_Width', 'R_Tire_Aspect_Ratio', and 'R_Tire_Diameter' in front for better organization. The original 'Rear_Tyre_&_Rim' column is dropped."""

width = data.columns.get_loc('R_Tire_Width')
aspect = data.columns.get_loc('R_Tire_Aspect_Ratio')
diameter = data.columns.get_loc('R_Tire_Diameter')
rear = data.columns.get_loc('Rear_Tyre_&_Rim')

# Move the columns to the desired positions
move_columns = data.pop('R_Tire_Width')
data.insert(rear,'R_Tire_Width',move_columns)

move_columns = data.pop('R_Tire_Aspect_Ratio')
data.insert(rear,'Tire_Aspect_Ratio',move_columns)

move_columns = data.pop('R_Tire_Diameter')
data.insert(rear,'R_Tire_Diameter',move_columns)

#The original 'Rear_Tyre_&_Rim' column is dropped.
data.drop(columns=['Rear_Tyre_&_Rim'],inplace=True)
#rename
data.rename(columns={'R_Tire_Width': 'R_Tire_Width_mm', 'R_Tire_Diameter': 'R_Tire_Diameter_inch'}, inplace=True)

"""### 13. Processing Power and Torque Datasets"""

data["Power"].head()

"""This code splits and extracts information from the 'Power' column into 'Power_PS' (power in PS) and 'Power_RPM' (power at RPM) columns, displaying the first five rows for reference."""

data[['Power_PS',"Power_RPM"]] = data['Power'].str.split("@",n=1,expand=True)
data[['Power_PS',"Power_RPM"]].head()

"""In this code, we clean the 'Power_PS' column by removing non-numeric characters and converting it to float type. The unique values in the cleaned column are then displayed."""

data["Power_PS"] = data["Power_PS"].replace(r'[A-Za-z]',"",regex=True)
#convert the data type
data["Power_PS"]=data["Power_PS"].astype(float)
data['Power_PS'].unique()

"""In this code, the 'Power_RPM' column is cleaned by removing non-numeric characters. Additionally, specific values are replaced, and the column is converted to float type. The unique values in the cleaned 'Power_RPM' column are then displayed."""

data['Power_RPM'] = data['Power_RPM'].replace(r'[A-Za-z]',"",regex=True)
# Replace specific values and convert to float type
data.loc[data["Power_RPM"].str.contains("-4",case=False,na=False),'Power_RPM'] = '4000'
data.loc[data['Power_RPM'].str.contains('-6', case=False, na=False), 'Power_RPM'] = '6000'
data.loc[data['Power_RPM'].str.contains('-7', case=False, na=False), 'Power_RPM'] = '7000'
# Display unique values in the cleaned 'Power_RPM' column of the 'car' DataFrame
data['Power_RPM'] = data['Power_RPM'].astype(float)
data['Power_RPM'].unique()

"""This code reorders and renames columns in the 'car' DataFrame, placing 'Power_PS' and 'Power_RPM' in front for better organization. The original 'Power' column is dropped."""

# Reorder and rename columns in 'car' DataFrame for better organization
index_of_Power_RPM = data.columns.get_loc('Power_RPM')
index_of_Power_PS = data.columns.get_loc('Power_PS')
index_of_Power = data.columns.get_loc('Power')

# Move the columns to the desired positions
column_to_move = data.pop('Power_PS')
data.insert(index_of_Power, 'Power_PS', column_to_move)

column_to_move = data.pop('Power_RPM')
data.insert(index_of_Power, 'Power_RPM', column_to_move)

# Drop the original 'Power' column
data.drop(columns=['Power'], inplace=True)

# Display the first five rows of 'Power_PS' and 'Power_RPM' columns in 'car' DataFrame
data[['Power_PS', 'Power_RPM']].head()

"""Here, we show the first five rows of the 'Torque' column in the 'car' DataFrame to provide a glimpse of the data."""

data["Torque"].head()

#split
data[["Torque_Nm","Torque_RPM"]] = data["Torque"].str.split("@",n=1,expand=True)
data[["Torque_Nm","Torque_RPM"]].head()

# Clean and convert 'Torque_Nm' column to float type
data['Torque_Nm'] = data['Torque_Nm'].replace(r'[A-Za-z]', '', regex=True)
data['Torque_Nm'] = data['Torque_Nm'].astype(float)

# Display unique values in the cleaned 'Torque_Nm' column of the 'data' DataFrame
data['Torque_Nm'].unique()

# Clean and convert 'Torque_RPM' column to float type
data['Torque_RPM'] = data['Torque_RPM'].replace(r'[A-Za-z]', '', regex=True)

# Replace specific values and convert to float type
data.loc[data['Torque_RPM'].str.contains('-1', case=False, na=False), 'Torque_RPM'] = '1000'
data.loc[data['Torque_RPM'].str.contains('-2', case=False, na=False), 'Torque_RPM'] = '2000'
data.loc[data['Torque_RPM'].str.contains('-3|- 3', case=False, na=False), 'Torque_RPM'] = '3000'
data.loc[data['Torque_RPM'].str.contains('-4|- 4', case=False, na=False), 'Torque_RPM'] = '4000'
data.loc[data['Torque_RPM'].str.contains('-5|- 5', case=False, na=False), 'Torque_RPM'] = '5000'
data.loc[data['Torque_RPM'].str.contains('-6', case=False, na=False), 'Torque_RPM'] = '6000'

data['Torque_RPM'] = data['Torque_RPM'].astype(float)

# Display unique values in the cleaned 'Torque_RPM' column of the 'data' DataFrame
data['Torque_RPM'].unique()

# Reorder and rename columns in 'car' DataFrame for better organization
index_of_Torque_RPM = data.columns.get_loc('Torque_RPM')
index_of_Torque_Nm = data.columns.get_loc('Torque_Nm')
index_of_Torque = data.columns.get_loc('Torque')

# Move the columns to the desired positions
column_to_move = data.pop('Torque_Nm')
data.insert(index_of_Torque, 'Torque_Nm', column_to_move)

column_to_move = data.pop('Torque_RPM')
data.insert(index_of_Torque, 'Torque_RPM', column_to_move)

# Drop the original 'Torque' column
data.drop(columns=['Torque'], inplace=True)

# Display the first five rows of 'Torque_Nm' and 'Torque_RPM' columns in 'data' DataFrame
data[['Torque_Nm', 'Torque_RPM']].head()

"""### 14. Processing Power_Steering, Power_Windows, Power_Seats and Keyless_Entry Datasets"""

data['Power_Steering'].unique()            # Display unique values in the 'Power_Steering' column of the 'car' DataFrame

"""In this code, values in the 'Power_Steering' column are replaced for better categorization. The modified unique values in the 'Power_Steering' column are then displayed."""

# Replace values in the 'Power_Steering' column for better categorization
data['Power_Steering'] = data['Power_Steering'].replace({'Electric Power, Hydraulic Power':'Electro-Hydraulic','Yes':'Undefined Powered',np.nan:'Non Powered'})

# Display unique values in the modified 'Power_Steering' column of the 'car' DataFrame
data['Power_Steering'].unique()

data['Power_Windows'].unique()

"""In this code, values in the 'Power_Windows' column are replaced for better categorization. The modified unique values in the 'Power_Windows' column are then displayed."""

# Replace values in the 'Power_Windows' column for better categorization
data['Power_Windows'] = data['Power_Windows'].replace({'Only Front Windows':'Front Windows',np.nan:'Non Powered'})

# Display unique values in the modified 'Power_Windows' column of the 'car' DataFrame
data['Power_Windows'].unique()

data['Power_Seats'].unique()

"""In this code, values in the 'Power_Seats' column are modified for better categorization. The modified unique values in the 'Power_Seats' column are then displayed"""

data.loc[data["Power_Seats"].str.contains('Yes|Power',case=False,na=False), "Power_Seats"] = "Powered Seats"
#replacing nan values
data["Power_Seats"] = data["Power_Seats"].replace(np.nan,"Not Powered")

#check unique values
data["Power_Seats"].unique()

"""
Now the, values in the 'Keyless_Entry' column are modified for better categorization. The modified unique values in the 'Keyless_Entry' column are then displayed."""

data["Keyless_Entry"].unique()

#modify values of keyless entry
data.loc[data["Keyless_Entry"].str.contains("Yes|Smart|Key|Remote",case=False,na=False), "Keyless_Entry"] = "Yes"
#replacing nan values
data["Keyless_Entry"] = data["Keyless_Entry"].replace(np.nan,"No")
#check for unique values
data["Keyless_Entry"].unique()

"""###15. Processing Other Features - Datasets

Now, we are displaying the unique values in the 'Odometer' column of the 'car' DataFrame.
"""

data['Odometer'].unique()

# Modify values in the 'Odometer' column for better categorization
data['Odometer'] = data['Odometer'].replace({'Digital, Analog':'Digi-Analog','Yes':'Unspecified'})

# Display unique values in the modified 'Odometer' column of the 'car' DataFrame
data['Odometer'].unique()

"""Now, we are displaying the unique values in the 'Speedometer' column of the 'car' DataFrame.



"""

data['Speedometer'].unique()

# Modify values in the 'Speedometer' column for better categorization
data['Speedometer'] = data['Speedometer'].replace({'Analog, Digital':'Digi-Analog','Digital, Analog':'Digi-Analog','Yes':'Unspecified'})

# Display unique values in the modified 'Speedometer' column of the 'car' DataFrame
data['Speedometer'].unique()

"""Now, we are displaying the unique values in the 'Tachometer' column of the 'car' DataFrame."""

data['Tachometer'].unique()

# Update values in the 'Tachometer' column for better categorization
data.loc[data['Tachometer'].str.contains('Yes|Analog|Digital|Not', case=False, na=False), 'Tachometer'] = 'Yes'
data.loc[data['Tachometer'].str.contains('Not', case=False, na=False), 'Tachometer'] = 'No'
data['Tachometer'] = data['Tachometer'].fillna('No')
print(data['Tachometer'].unique())

"""Now, we are displaying the value counts for the 'Tripmeter' column in the 'car' DataFrame."""

data["Tripmeter"].unique()

data["Tripmeter"].value_counts()

"""Now, we have updated the 'Tripmeter' column by setting non-null values to 'Yes' and replacing remaining NaN values with 'No'. The updated value counts are displayed."""

data["Tripmeter"] = np.where(data["Tripmeter"].notnull(), "Yes", data["Tripmeter"])
data["Tripmeter"] = data["Tripmeter"].replace(np.nan,"No")
data["Tripmeter"].unique()

data["Tripmeter"].value_counts()

"""Now, we are randomly sampling 5 entries from the 'Wheelbase' column in the 'car' DataFrame to get an overview of its values"""

data["Wheelbase"].sample(5)

"""Now, we have cleaned and converted the 'Wheelbase' column to numerical values in millimeters, renaming it as 'Wheelbase_mm' in the process."""

data["Wheelbase"] = data["Wheelbase"].str.replace(r'\D',"",regex=True)
#rename
data.rename(columns={"Wheelbase":"Wheelbase_mm"},inplace=True)
#convert data type
data["Wheelbase_mm"].astype(float)
#check  values
data["Wheelbase_mm"].unique()

"""we have removed the 'Wheels_Size' column from the 'car' DataFrame ad we have earlier determined the wheelbase and tire size"""

data.drop(columns=["Wheels_Size"],inplace=True)

"""Now, we can see the unique values in the cleaned 'Basic_Warranty' column of the 'car' DataFrame"""

data['Basic_Warranty'].unique()                # Display unique values in the cleaned 'Basic_Warranty' column

# Update the 'Basic_Warranty' column in the 'data' DataFrame based on the specified conditions
data.loc[data['Basic_Warranty'].str.contains('1 Year', na=False), 'Basic_Warranty'] = '1'
data.loc[data['Basic_Warranty'].str.contains('2 years|2 Years|24 months', na=False), 'Basic_Warranty'] = '2'
data.loc[data['Basic_Warranty'].str.contains('3 years|3 Years|3rd years', na=False), 'Basic_Warranty'] = '3'
data.loc[data['Basic_Warranty'].str.contains('4 years', na=False), 'Basic_Warranty'] = '4'
data.loc[data['Basic_Warranty'].str.contains('8 yrs', na=False), 'Basic_Warranty'] = '8'

# Rename the 'Basic_Warranty' column to 'Basic_Warranty_years' and convert to float
data.rename(columns={'Basic_Warranty': 'Basic_Warranty_years'}, inplace=True)
data['Basic_Warranty_years'] = data['Basic_Warranty_years'].astype(float)

data['Basic_Warranty_years'].value_counts()          # Display the value counts for the 'Basic_Warranty_years' column in the 'car' DataFrame

"""This code snippet will show the unique values present in the 'Boot_Space' column of the 'car' DataFrame"""

data['Boot_Space'].unique()

# Clean and convert 'Boot_Space' column to float type
data['Boot_Space'] = data['Boot_Space'].replace('209(All3RowsUp).550(3rdRowFolded)&803(2ndRowand3rdRowFolded) litres',np.nan)
data['Boot_Space'] = data['Boot_Space'].replace(r'\D', '', regex=True)
data.rename(columns={'Boot_Space': 'Boot_Space_litres'}, inplace=True)
data['Boot_Space_litres'] = data['Boot_Space_litres'].astype(float)
data['Boot_Space_litres'].unique()

"""Now we have dropped the 'Extended_Warranty' column from the 'car' DataFrame as we no further require the warranty."""

data.drop(columns='Extended_Warranty', inplace=True)             # Drop the 'Extended_Warranty' column from the 'car' DataFrame

"""Now we will process the 'Minimum_Turning_Radius' column in the 'car' DataFrame."""

data['Minimum_Turning_Radius'].unique()

# Removing non-digit characters from the 'Minimum_Turning_Radius' column
data['Minimum_Turning_Radius'] = data['Minimum_Turning_Radius'].replace(r'\D', '', regex=True)

# Renaming the column to provide a more descriptive name
data.rename(columns={'Minimum_Turning_Radius': 'Minimum_Turning_Radius_meter'}, inplace=True)

# Converting the values in 'Minimum_Turning_Radius_meter' to float data type
data['Minimum_Turning_Radius_meter'] = data['Minimum_Turning_Radius_meter'].astype(float)

"""# **Handling Null Values**

Dealing with the NULL values present over the dataset.

Now, we produce summary statistics for the numerical columns in the updated 'car' DataFrame,
"""

data.describe()

#display the datatypes of each columns
for i in data:
  print(i,"-----",data[i].dtype)

data.isnull().sum().sum()          # Sum of all missing values in the 'car' DataFrame

"""In this code, missing values in numeric columns of the 'car' DataFrame are imputed with the median of each respective column."""

# Impute missing values with the median for numeric columns in the 'car' DataFrame
numeric=["int32","float64"]

for j in data.columns:
    if data[j].dtype in numeric:
        if data[j].isnull().sum()>0:
            data[j]=data[j].fillna(data[j].median())

"""Here, we print the count of missing values in numeric columns of the 'car' DataFrame, providing insights into the remaining missing values after the imputation process."""

# Display the count of missing values in numeric columns of the 'car' DataFrame
for j in data.columns:
    if data[j].dtype in numeric:
        print(j,'--------',data[j].isnull().sum())

data.isnull().sum().sum()    # Sum of all remaining missing values in the 'car' DataFrame

"""Here, we define a list named 'vital' containing a subset of important columns selected from the 'car' DataFrame. These columns are considered vital for analysis and understanding the key features of the dataset."""

# Selecting a subset of vital columns from the 'car' DataFrame
vital = ['Make', 'Model', 'Variant', 'Ex-Showroom_Price_INR', 'Drivetrain', 'Cylinder_Configuration',
 'Emission_Norm', 'Engine_Location', 'Fuel_System', 'Fuel_Type', 'Body_Type', 'Front_Brakes', 'Rear_Brakes',
 'Front_Suspension', 'Rear_Suspension', 'Power_Steering', 'Power_Windows', 'Power_Seats', 'Odometer', 'Speedometer',
 'Seats_Material', 'Type']

"""In this code, missing values in the vital columns of the 'car' DataFrame are filled with the placeholder 'unspecified' to handle any remaining null values."""

# Fill missing values in vital columns with 'unspecified' in the 'car' DataFrame
for i in vital:
    data[i]=data[i].fillna('unspecified')

data.isnull().sum().sum()          # Sum of all remaining missing values in the 'car' DataFrame after filling with 'unspecified'

"""Here, we iterate through the columns of the 'car' DataFrame and append non-numeric features that are not part of the vital columns to the 'features' list."""

# Extract non-numeric features not included in the vital columns
features = []
for i in data.columns:
    if i not in vital:
        if data[i].dtype not in numeric:
            features.append(i)

features[:5]      # Display the first 5 non-numeric features

"""In this code, non-numeric features in the 'car' DataFrame are converted to binary indicators, where 'Yes' indicates the presence of a value, and 'No' indicates a missing value."""

# Convert non-numeric features to binary indicators ('Yes' or 'No') in the 'car' DataFrame
for k in features:
    data[k] = np.where(data[k].notnull(), 'Yes', data[k])
    data[k] = data[k].fillna('No')

data.isnull().sum().sum()  # Sum of all remaining missing values in the 'car' DataFrame after converting to binary indicators

"""#**Viewing & Saving Clean Data**

Viewing the final and cleaned data, saving it into .csv format

Here, the column names in the 'car' DataFrame are modified by replacing spaces with underscores and converting them to lowercase for consistency.
"""

data.columns = [col.replace(' ', '_').lower() for col in data.columns]

data.sample(5)                 # Display a random sample of 5 rows from the modified 'car' DataFrame

print(data.dtypes)       # Display data types of each column in the modified 'car' DataFrame

print(data.isnull().sum().sum())               # Sum of all remaining missing values in the modified 'car' DataFrame

print(data.info())           # Display concise information about the modified 'car' DataFrame

"""Here, the modified 'car' DataFrame is saved to a CSV file named 'car_data_cleaned.csv' without including the index column."""

data.to_csv("'car_data_cleaned.csv",index=False)

"""#**Statistics & Data Vizualization**

## Data Analysis

### 1.1. Descriptive Numeric Analysis
"""

# Generate descriptive statistics for numerical columns in the 'stores' DataFrame
data.describe()

"""### 1.2. Descriptive Object Analysis"""

data.describe(include=["object"])

"""### 2. Top Car Models

Here, we calculate the average ex-showroom price for each car model, group the data by make and model, and then display the top 5 car models based on the highest average ex-showroom price.
"""

top_car_models = data.groupby(["make","model"])['ex-showroom_price_inr'].mean().sort_values(ascending=False).head(5)
print(top_car_models)

"""### 3. Cheapest Car Models

Here, we calculate the average ex-showroom price for each car model, group the data by make and model, and then display the 5 cheapest car models based on the lowest average ex-showroom price.
"""

# Find and display the cheap 5 car models based on the ex-showroom price
cheapest_car_models = data.groupby(['make', 'model'])['ex-showroom_price_inr'].mean().sort_values(ascending=True).head(5)
print("Top Car Models:\n", cheapest_car_models)

"""### 4. Popular Fuel Types

In this step, we identify and display the top 5 most popular fuel types based on their count in the 'car' DataFrame.
"""

# Find and display the most popular fuel types based on the count
popular_fuel_types = data['fuel_type'].value_counts().head(5).reset_index()
print("Popular Fuel Types:\n", popular_fuel_types)

"""## **Data Vizualization: `Univariate`**

### 1. **Histogram**

Here, we create a side-by-side histogram subplot for the distribution of ex-showroom prices and the count of features in the 'car' DataFrame. The first subplot uses a log scale for better visualization of ex-showroom prices.
"""

# Create a side-by-side histogram subplot for ex-showroom prices and the number of features
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# First subplot for ex-showroom prices distribution
log_bins = np.logspace(np.log10(data['ex-showroom_price_inr'].min()), np.log10(data['ex-showroom_price_inr'].max()), 20)
axes[0].hist(data['ex-showroom_price_inr'].dropna(), bins=log_bins, color='skyblue', edgecolor='black')
axes[0].set_title('Distribution of Ex-showroom Prices')
axes[0].set_xlabel('Ex-showroom Price (INR)')
axes[0].set_ylabel('Frequency')
axes[0].set_xscale('log')  # Set x-axis to log scale

# Second subplot for the count of features
sns.histplot(data['num_features'].dropna(), bins=30, color='lightgreen', edgecolor='black', ax=axes[1])
axes[1].set_title('Histogram of Features Count')
axes[1].set_xlabel('Number of Features')
axes[1].set_ylabel('Frequency')

# Adjust layout to prevent overlapping
plt.tight_layout()
plt.show()

"""### 2. **Bar Charts**

This code creates a side-by-side bar plot with two subplots. The first subplot shows the count of car makes to visualize the diversity of car makes. The second subplot displays the count of variants for the top-diverse model from each make.
"""

# Create a side-by-side bar plot for car makes and top-diverse models
fig, axes = plt.subplots(1, 2, figsize=(16, 5))

# First subplot for car makes
sns.countplot(data=data, x='make', palette='viridis', order=data['make'].value_counts().index, ax=axes[0])
axes[0].set_title('Count of Diversity of Car Makes')
axes[0].set_xlabel('Car Make')
axes[0].set_ylabel('Total Count they Offer')
axes[0].tick_params(axis='x', rotation=90)

# Identify the top-diverse model for each make
top_models_by_make = data.groupby('make')['model'].apply(lambda x: x.value_counts().idxmax())

# Filter the car DataFrame to include only the rows corresponding to the top-selling models
top_diverse_cars = data[data['model'].isin(top_models_by_make)]

# Second subplot for top-diverse models
sns.countplot(data=top_diverse_cars, x='model', order=top_diverse_cars['model'].value_counts().index, palette='viridis', ax=axes[1])
axes[1].set_title('Top-Diverse Model from Each Make')
axes[1].set_xlabel('Car Model')
axes[1].set_ylabel('Counts of Variants')
axes[1].tick_params(axis='x', rotation=90)

# Adjust layout to prevent overlapping
plt.tight_layout()
plt.show()

# Calculate the counts of makes and price segments
make_counts = data.groupby(['make']).size().reset_index(name='count')

# Sort the makes in descending order based on the total count
sorted_makes = make_counts.groupby('make')['count'].sum().sort_values(ascending=False).index

# Create a stacked bar chart using plotly
fig = px.bar(make_counts, x='make', y='count', title='Counts of Makes by Price Segment',
             labels={'make': 'Make', 'count': 'Count', 'price_segment': 'Price Segment'}, height=500,
             category_orders={'make': sorted_makes})

# Customize the layout
fig.update_layout(xaxis=dict(tickangle=-45, tickmode='array', tickvals=list(range(len(sorted_makes))),
                             ticktext=sorted_makes))

# Show the chart
fig.show()

# Define the desired body types
desired_body_types = ['Coupe', 'Crossover', 'Hatchback', 'MPV', 'MUV', 'Pick-up', 'Sedan', 'Sports', 'SUV']

# Filter the DataFrame to include only the desired body types
filtered_car = data[data['body_type'].isin(desired_body_types)]

# Create side-by-side bar charts for fuel type and body type distribution
fig, axes = plt.subplots(1, 2, figsize=(16, 4))

# Bar chart for fuel type distribution
sns.countplot(data=data, x='fuel_type',width = 0.5, order=data['fuel_type'].value_counts().index, palette='viridis', ax=axes[0])
axes[0].set_yscale('log')
axes[0].set_title('Count of Cars by Fuel Type')
axes[0].set_xlabel('Fuel Type')
axes[0].set_ylabel('Count (log scale)')

# Bar chart for filtered body type distribution
sns.countplot(data=filtered_car, x='body_type', order=filtered_car['body_type'].value_counts().index, palette='viridis', ax=axes[1])
axes[1].set_yscale('log')
axes[1].set_title('Count of Cars by Desired Body Types')
axes[1].set_xlabel('Body Type')
axes[1].set_ylabel('Count (log scale)')

# Adjust layout to prevent overlapping
plt.tight_layout()
plt.show()

"""### 3. **Box Plots**

Here, we create a 2x2 matrix of box plots for different features in the 'car' DataFrame, showcasing the distribution and variability of ex-showroom prices, ARAI certified mileage, number of cylinders, and number of doors. The x-axis for ex-showroom prices is displayed on a log scale for better visualization.
"""

# Create a 2x2 matrix of box plots
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Box plot for ex-showroom prices
sns.boxplot(data=data, x='ex-showroom_price_inr', color='lightblue', ax=axes[0, 0])
axes[0, 0].set_xscale('log')
axes[0, 0].set_title('Ex-showroom Prices')
axes[0, 0].set_xlabel('Ex-showroom Price (INR)')

# Box plot for ARAI certified mileage
sns.boxplot(data=data, x='arai_certified_mileage_kmpl', color='lightgreen', ax=axes[0, 1])
axes[0, 1].set_title('ARAI Certified Mileage (kmpl)')
axes[0, 1].set_xlabel('ARAI Certified Mileage (kmpl)')

# Box plot for cylinders
sns.boxplot(data=data, x='cylinders', color='lightcoral', ax=axes[1, 0])
axes[1, 0].set_title('Cylinders')
axes[1, 0].set_xlabel('Number of Cylinders')

# Box plot for doors
sns.boxplot(data=data, x='doors', color='lightskyblue', ax=axes[1, 1])
axes[1, 1].set_title('Doors')
axes[1, 1].set_xlabel('Number of Doors')

# Adjust layout
plt.tight_layout()
plt.show()

"""### 4. **Pie Charts**

In this function, we take a data series and a threshold percentage as inputs. The function calculates the percentages of each category in the series and creates a mask to identify categories exceeding the specified threshold percentage. Categories below the threshold are grouped into 'Others,' and the resulting grouped series is returned.
"""

# Function to group small percentages into 'Other'
def group_small_percentages(data_series, threshold_percent=10):
    percentages = data_series.value_counts(normalize=True) * 100
    mask = percentages >= threshold_percent
    grouped_series = data_series.apply(lambda x: x if mask.get(x, False) else 'Others')
    return grouped_series

"""In this code, we remove 'unspecified' values from each column in the 'car' DataFrame and then create a 2x2 matrix of pie charts to visualize the distribution of drivetrain types, emission norms, fuel types, and desired body types in the market. The 'group_small_percentages' function is utilized to handle small percentages and group them into 'Others' for better visualization."""

# Remove 'unspecified' values from each column
car_no_unspecified = data.replace('unspecified', np.nan).dropna()

# Create a 2x2 matrix for pie charts
plt.figure(figsize=(10, 8))

# Pie chart for Drivetrain
plt.subplot(2, 2, 1)
drivetrain_distribution = car_no_unspecified['drivetrain'].value_counts()
plt.pie(drivetrain_distribution, labels=drivetrain_distribution.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('crest'))
plt.title('Distribution of Drivetrain Types')
plt.legend(loc='lower left', fontsize='small')

# Pie chart for Emission Norm
plt.subplot(2, 2, 2)
emission_norm_distribution = car_no_unspecified['emission_norm'].value_counts()
plt.pie(emission_norm_distribution, labels=emission_norm_distribution.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('crest'))
plt.title('Distribution of Emission Norms')
plt.legend(loc='lower left', fontsize='small')

# Pie chart for Fuel Type
plt.subplot(2, 2, 3)
fuel_type_distribution = group_small_percentages(car_no_unspecified['fuel_type'])
plt.pie(fuel_type_distribution.value_counts(), labels=fuel_type_distribution.value_counts().index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('crest'))
plt.title('Distribution of Fuel Types')
plt.legend(loc='lower left', fontsize='small')

# Pie chart for Desired Body Types
plt.subplot(2, 2, 4)
body_type_distribution = group_small_percentages(filtered_car['body_type'])
plt.pie(body_type_distribution.value_counts(), labels=body_type_distribution.value_counts().index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('crest'))
plt.title('Distribution of Desired Body Types in the Market')
plt.legend(loc='lower left', fontsize='small')

plt.tight_layout()
plt.show()

"""Here, we are visualizing the distribution of the top 6 car makes and market-dominating car models using pie charts. The first subplot shows the distribution of the top 6 car makes, while the second subplot illustrates the distribution of the top 6 market-dominating car models."""

# Select the top 6 makes and market-dominating models based on counts
top_makes = data['make'].value_counts().head(6)
top_models = data['model'].value_counts().head(6)

# Create a 1x2 matrix of subplots
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Plot the pie chart for top makes in the first subplot (axes[0])
axes[0].pie(top_makes, labels=top_makes.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('crest'))
axes[0].set_title('Distribution of Top 6 Car Makes')

# Plot the pie chart for top models in the second subplot (axes[1])
axes[1].pie(top_models, labels=top_models.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('crest'))
axes[1].set_title('Distribution of Top 6 Market Dominating Car Models')

# Adjust layout for better spacing
plt.tight_layout()

# Show the plots
plt.show()

"""### 5. **Count Plots**

Here, we create a 3x3 matrix of subplots to visualize count plots for various categorical columns in the 'car' DataFrame. Each subplot focuses on different aspects like drivetrain, fuel type, cylinder configuration, engine location, number of doors, number of gears, transmission type, and body type. The use of logarithmic scale on the y-axis enhances visibility.
"""

fig, axes = plt.subplots(3, 3, figsize=(15, 15))

# Count plot for drivetrain
sns.countplot(data=car_no_unspecified, x='drivetrain', ax=axes[0, 0], palette='viridis', order=car_no_unspecified['drivetrain'].value_counts().index, width=0.5)
axes[0, 0].set_title('Count of Cars by Drivetrain')
axes[0, 0].set_xlabel('Drivetrain')
axes[0, 0].set_yscale('log')

# Count plot for fuel type
sns.countplot(data=car_no_unspecified, x='fuel_type', ax=axes[0, 1], palette='viridis', order=car_no_unspecified['fuel_type'].value_counts().index, width=0.5)
axes[0, 1].set_title('Count of Cars by Fuel Type')
axes[0, 1].tick_params(axis='x', rotation=90)
axes[0, 1].set_xlabel('Fuel Type')
axes[0, 1].set_yscale('log')

# Count plot for cylinder configuration
sns.countplot(data=car_no_unspecified, x='cylinder_configuration', ax=axes[0, 2], palette='viridis', order=car_no_unspecified['cylinder_configuration'].value_counts().index, width=0.5)
axes[0, 2].set_title('Count of Cars by Cylinder Configuration')
axes[0, 2].set_xlabel('Cylinder Configuration')
axes[0, 2].set_yscale('log')

# Count plot for engine location
sns.countplot(data=car_no_unspecified, x='engine_location', ax=axes[1, 0], palette='viridis', order=car_no_unspecified['engine_location'].value_counts().index, width=0.5)
axes[1, 0].set_title('Count of Cars by Engine Location')
axes[1, 0].tick_params(axis='x', rotation=90)
axes[1, 0].set_xlabel('Engine Location')
axes[1, 0].set_yscale('log')

# Count plot for doors
sns.countplot(data=car_no_unspecified, x='doors', ax=axes[1, 1], palette='viridis', order=car_no_unspecified['doors'].value_counts().index, width=0.5)
axes[1, 1].set_title('Count of Cars by Number of Doors')
axes[1, 1].set_xlabel('Number of Doors')
axes[1, 1].set_yscale('log')

# Count plot for gears
sns.countplot(data=car_no_unspecified, x='gears', ax=axes[1, 2], palette='viridis', order=car_no_unspecified['gears'].value_counts().index, width=0.5)
axes[1, 2].set_title('Count of Cars by Number of Gears')
axes[1, 2].set_xlabel('Number of Gears')
axes[1, 2].set_yscale('log')

# Count plot for type
sns.countplot(data=car_no_unspecified, x='type', ax=axes[2, 0], palette='viridis', order=car_no_unspecified['type'].value_counts().index, width=0.5)
axes[2, 0].set_title('Count of Cars by Transmission Type')
axes[2, 0].set_xlabel('Transmission Type')
axes[2, 0].set_yscale('log')

# Count plot for body type
sns.countplot(data=filtered_car, x='body_type', ax=axes[2, 1], palette='viridis', order=filtered_car['body_type'].value_counts().index, width=0.5)
axes[2, 1].set_title('Count of Cars by Body Type')
axes[2, 1].tick_params(axis='x', rotation=90)
axes[2, 1].set_xlabel('Body Type')
axes[2, 1].set_yscale('log')

# Hide the empty subplot in the last row and last column
axes[2, 2].axis('off')

plt.tight_layout()
plt.show()

"""## **Data Vizualization: `Bivariate`**

### 1. **Correlation Matrix**
"""

# Select the dimensions and calculate the correlation matrix
dimension_subset = data[['height_mm', 'length_mm', 'width_mm', 'kerb_weight_kg', 'ground_clearance_mm']].corr()

# Display the correlation matrix
dimension_subset

# Select the specified columns and calculate the correlation matrix
correlation_matrix_tire = data[['front_track_mm', 'rear_track_mm', 'f_tire_diameter_inch', 'f_tire_aspect_ratio',
                               'f_tire_width_mm', 'r_tire_diameter_inch',  'r_tire_width_mm']].corr()

# Display the correlation matrix
correlation_matrix_tire

# Select the specified columns and calculate the correlation matrix
correlation_matrix_power_torque = data[['power_rpm', 'power_ps', 'torque_rpm', 'torque_nm']].corr()

# Display the correlation matrix
correlation_matrix_power_torque

# Select the specified columns and calculate the correlation matrix
correlation_matrix_gears_doors_features = data[['gears', 'doors']].corr()

# Display the correlation matrix
correlation_matrix_gears_doors_features

"""### 2. **Scatter Plots**

Here, we create a scatter plot to visualize the relationship between the ex-showroom price and the number of features for each car. The x-axis is scaled logarithmically for better clarity
"""

fig, axs = plt.subplots(2, 2, figsize=(14, 8))

# Scatter plot between car make and ex-showroom price
sns.scatterplot(x='make', y='ex-showroom_price_inr', data=data, palette='viridis', ax=axs[0, 0])
axs[0, 0].set_title('Car Make vs Ex-showroom Price')
axs[0, 0].set_xlabel('Car Make')
axs[0, 0].set_ylabel('Ex-showroom Price (INR)')
axs[0, 0].set_yscale('log')
axs[0, 0].tick_params(axis='x', rotation=90,labelsize=8)

# Scatter plot between ARAI certified mileage and fuel type
sns.scatterplot(x='arai_certified_mileage_kmpl', y='fuel_type', data=data, hue='fuel_type', palette='viridis', ax=axs[0, 1])
axs[0, 1].set_title('ARAI Certified Mileage vs Fuel Type')
axs[0, 1].set_xlabel('ARAI Certified Mileage (kmpl)')
axs[0, 1].set_ylabel('Fuel Type')
axs[0, 1].legend(title='Fuel Type', bbox_to_anchor=(1.05, 1), loc='upper left')

# Scatter plot between fuel type and cylinder configuration
sns.scatterplot(x='fuel_type', y='cylinder_configuration', data=car_no_unspecified, hue='fuel_type', palette='viridis', ax=axs[1, 0])
axs[1, 0].set_title('Fuel Type vs Cylinder Configuration')
axs[1, 0].set_xlabel('Fuel Type')
axs[1, 0].set_ylabel('Cylinder Configuration')
axs[1, 0].legend(title='Fuel Type')

# Scatter plot between fuel type and car type
sns.scatterplot(x='fuel_type', y='type', data=car_no_unspecified, hue='fuel_type', palette='viridis', ax=axs[1, 1])
axs[1, 1].set_title('Fuel Type vs Car Type')
axs[1, 1].set_xlabel('Fuel Type')
axs[1, 1].set_ylabel('Car Type')
axs[1, 1].legend(title='Fuel Type', bbox_to_anchor=(1.05, 1), loc='upper left')

plt.tight_layout()
plt.show()

"""### Pair Plots

We create a pairplot to visualize relationships between selected numeric variables (height, length, width, kerb weight, and ground clearance) in the 'car' DataFrame. The data is subsampled to improve plot readability. The title is added for clarity.
"""

# Pairplot for selected numeric variables
selected_numeric_variables = ['height_mm', 'length_mm', 'width_mm', 'kerb_weight_kg', 'ground_clearance_mm']
# Subsample the data
subsampled_data = data.sample(frac=0.2, random_state=42)

# Pairplot for selected numeric variables with subsampled data
sns.pairplot(subsampled_data[selected_numeric_variables])
plt.suptitle('Pairplot of Selected Numeric Variables (Subsampled Data)', y=1.02)
plt.show()

# Selected numeric variables
selected_power_torque_variables = ['power_rpm', 'power_ps', 'torque_rpm', 'torque_nm']

# Pairplot for selected power and torque variables
sns.pairplot(data[selected_power_torque_variables])
plt.suptitle('Pairplot of Power and Torque Variables', y=1.02)
plt.show()

"""### 4. **Bar Charts**

To explore the relationship between the number of features, price segment, and specific car models. The first chart displays the count of cars based on the number of features and price segment. The second and third charts showcase the top 5 expensive and cheapest car models along with the corresponding number of features. Legends, titles, and axis labels are provided for better interpretation.
"""

# Create the 'num_features' column
data['num_features'] = data.notnull().sum(axis=1) - 1  # Subtracting 1 to exclude the index column

# Create bins for the number of features
feature_bins = [0, 10, 20, 30, 40, float('inf')]
feature_labels = ['0-10', '11-20', '21-30', '31-40', '41+']
data['feature_bins'] = pd.cut(data['num_features'], bins=feature_bins, labels=feature_labels, right=False)

# Create the 'price_segment' column to categorize cars into different price segments
data['price_segment'] = pd.cut(data['ex-showroom_price_inr'], bins=[0, 500000, 1000000, 2000000, 5000000, float('inf')],
                               labels=['Budget', 'Mid-range', 'Premium', 'Luxury', 'Ultra Luxury'], right=False)

# Find the top 5 unique car models with the highest ex-showroom prices
top_expensive_models = data.sort_values(by='ex-showroom_price_inr', ascending=False).drop_duplicates(subset='model').head(5)

# Find the top 5 unique car models with the lowest ex-showroom prices
top_cheapest_models = data.sort_values(by='ex-showroom_price_inr', ascending=True).drop_duplicates(subset='model').head(5)

# Create a 1x3 matrix of subplots
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

# Plot the first chart (Number of Features vs Price Segment)
sns.countplot(data=data, x='feature_bins', hue='price_segment', palette='viridis', ax=axes[0])
axes[0].set_title('Number of Features vs Price Segment')
axes[0].set_xlabel('Number of Features')
axes[0].set_ylabel('Count')

# Plot the second chart (Top 5 Expensive Car Models vs Number of Features)
sns.barplot(data=top_expensive_models, x='model', y='num_features', palette='viridis', ax=axes[1])
axes[1].set_title('Top 5 Expensive Car Models vs Number of Features')
axes[1].set_xlabel('Car Model')
axes[1].set_ylabel('Number of Features')
axes[1].tick_params(axis='x', rotation=45)

# Plot the third chart (Top 5 Cheapest Car Models vs Number of Features)
sns.barplot(data=top_cheapest_models, x='model', y='num_features', palette='viridis', ax=axes[2])
axes[2].set_title('Top 5 Cheapest Car Models vs Number of Features')
axes[2].set_xlabel('Car Model')
axes[2].set_ylabel('Number of Features')
axes[2].tick_params(axis='x', rotation=45)

# Adjust layout
plt.tight_layout()
plt.show()

"""### 5. **Heatmaps**

Here, we choose specific dimensions from the 'car' DataFrame and compute the correlation matrix. The resulting heatmap visually represents the correlation coefficients between these dimension variables.
"""

# Select the dimensions and calculate the correlation matrix
dimension_subset = data[['height_mm', 'length_mm', 'width_mm', 'kerb_weight_kg', 'ground_clearance_mm']].corr()

# Create a heatmap for the correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(dimension_subset, annot=True, cmap='crest', fmt=".2f", linewidths=.5)
plt.title('Correlation Heatmap for Dimension Variables')
plt.show()

# Select the specified columns and calculate the correlation matrix
correlation_matrix_tire = data[['front_track_mm', 'rear_track_mm', 'f_tire_diameter_inch', 'f_tire_aspect_ratio',
                               'f_tire_width_mm', 'r_tire_diameter_inch', 'r_tire_width_mm']].corr()

# Create a heatmap for the correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix_tire, annot=True, cmap='crest', fmt=".2f", linewidths=.5)
plt.title('Correlation Heatmap for Tire-related Variables')
plt.show()

# Select the specified columns and calculate the correlation matrix
correlation_matrix_power_torque = data[['power_rpm', 'power_ps', 'torque_rpm', 'torque_nm']].corr()

# Create a heatmap for the correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix_power_torque, annot=True, cmap='crest', fmt=".2f", linewidths=.5)
plt.title('Correlation Heatmap for Power and Torque Variables')
plt.show()

"""### 6. **Joint Plots**"""

# Define the desired body types
desired_body_types = ['Coupe', 'Crossover', 'Hatchback', 'MPV', 'MUV', 'Pick-up', 'Sedan', 'Sports', 'SUV']

# Filter the DataFrame to include only the desired body types and create a copy to avoid warnings
filtered_data = data[data['body_type'].isin(desired_body_types)].copy()

# Ensure 'arai_certified_mileage_kmpl' is numeric
filtered_data['arai_certified_mileage_kmpl'] = pd.to_numeric(filtered_data['arai_certified_mileage_kmpl'], errors='coerce')

# Create a new column for the log of the price
filtered_data['log_price'] = np.log1p(filtered_data['ex-showroom_price_inr'])

# Joint plot for Price vs Mileage vs Body type
plt.figure(figsize=(8, 6))
joint_plot = sns.jointplot(data=filtered_data, x='log_price', y='arai_certified_mileage_kmpl', hue='body_type', height=8)
joint_plot.set_axis_labels('Log(Ex-showroom Price) INR', 'ARAI Certified Mileage (kmpl)')
joint_plot.fig.suptitle('Joint Plot for Log(Price) vs Mileage vs Body Type', y=1.02)
plt.show()

# Remove the temporary log_price column
filtered_data.drop('log_price', axis=1, inplace=True)

"""Here, we generate a joint plot to explore the relationships between car length and width, considering different fuel types. The plot provides insights into how these dimensions vary across various fuel types."""

# Joint plot for Length vs Width vs Fuel type
plt.figure(figsize=(12, 8))

joint_plot = sns.jointplot(data=data, x='length_mm', y='width_mm', hue='fuel_type', height=8)
joint_plot.set_axis_labels('Length (mm)', 'Width (mm)')
joint_plot.fig.suptitle('Joint Plot for Length vs Width vs Fuel Type', y=1.02)
plt.show()

"""### 7. **Box Plots**"""

# Ensure 'arai_certified_mileage_kmpl' is numeric
data['arai_certified_mileage_kmpl'] = pd.to_numeric(data['arai_certified_mileage_kmpl'], errors='coerce')

# Ensure 'minimum_turning_radius_meter' is numeric
data['minimum_turning_radius_meter'] = pd.to_numeric(data['minimum_turning_radius_meter'], errors='coerce')

# Filter the DataFrame to include only the desired body types
desired_body_types = ['Coupe', 'Crossover', 'Hatchback', 'MPV', 'MUV', 'Pick-up', 'Sedan', 'Sports', 'SUV']
filtered_car = data[data['body_type'].isin(desired_body_types)].copy()

# Ensure 'wheelbase_mm' is numeric for ordering
filtered_car['wheelbase_mm'] = pd.to_numeric(filtered_car['wheelbase_mm'], errors='coerce')

# Create a 2x2 matrix of subplots
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))

# 1. Affordable vs Price (in log)
sns.boxplot(data=data, x='price_segment', y=np.log1p(data['ex-showroom_price_inr']), hue='price_segment', palette='viridis', dodge=False, ax=axes[0, 0])
axes[0, 0].set_title('Affordable vs Price (in log)')
axes[0, 0].set_xlabel('Affordability')
axes[0, 0].set_ylabel('Log(Ex-showroom Price)')

# 2. Fuel Type vs Mileage
sns.boxplot(data=data, x='fuel_type', y='arai_certified_mileage_kmpl', hue='fuel_type', palette='viridis', dodge=False, ax=axes[0, 1])
axes[0, 1].set_title('Fuel Type vs Mileage')
axes[0, 1].set_xlabel('Fuel Type')
axes[0, 1].set_ylabel('ARAI Certified Mileage (kmpl)')

# 3. Body Type vs Doors (corrected line)
sns.boxplot(data=filtered_car, x='body_type', y='doors', hue='body_type', palette='viridis', dodge=False, ax=axes[1, 0])
axes[1, 0].set_title('Body Type vs Doors')
axes[1, 0].set_xlabel('Body Type')
axes[1, 0].set_ylabel('Number of Doors')

# 4. Wheel Size vs Minimum Turning Radius (with y-axis in log scale)
sns.boxplot(data=data, x='f_tire_diameter_inch', y='minimum_turning_radius_meter', hue='f_tire_diameter_inch', palette='viridis', dodge=False, ax=axes[1, 1])
axes[1, 1].set_title('Wheel Size vs Minimum Turning Radius (meters)')
axes[1, 1].set_xlabel('Front Tire Diameter (inch)')
axes[1, 1].set_ylabel('Minimum Turning Radius (meters)')
axes[1, 1].set_yscale('log')

# Adjust layout for better spacing
plt.tight_layout()
plt.show()

"""### 8. **Categorical Plots**

Here, we use a 3x2 matrix of subplots to display categorical plots. The plots include counts of cars by body type, number of doors, number of gears, affordability vs price, fuel type, and engine type
"""

# Create a 3x2 matrix for categorical plots
fig, axes = plt.subplots(3, 2, figsize=(15, 15))

desired_body_types = ['Coupe', 'Crossover', 'Hatchback', 'MPV', 'MUV', 'Pick-up', 'Sedan', 'Sports', 'SUV']

# Filter the DataFrame to include only the desired body types
filtered_car = data[data['body_type'].isin(desired_body_types)]

# Order the body types by mean count in descending order
order_body_types_count = filtered_car['body_type'].value_counts().sort_values(ascending=False).index

# Plot 1: Body Type
sns.countplot(data=filtered_car, x='body_type', palette='viridis', order=order_body_types_count, width=0.5, ax=axes[0, 0])
axes[0, 0].set_title('Count of Cars by Body Type')
axes[0, 0].set_xlabel('Body Type')
axes[0, 0].set_ylabel('Count')

# Plot 2: Doors
sns.countplot(data=data, x='doors', palette='viridis', order=data['doors'].value_counts().sort_values(ascending=False).index, width=0.5, ax=axes[0, 1])
axes[0, 1].set_title('Count of Cars by Number of Doors')
axes[0, 1].set_xlabel('Number of Doors')
axes[0, 1].set_ylabel('Count')
axes[0, 1].set_yscale('log')

# Plot 3: Gears
sns.countplot(data=data, x='gears', palette='viridis', order=data['gears'].value_counts().sort_values(ascending=False).index, width=0.5, ax=axes[1, 0])
axes[1, 0].set_title('Count of Cars by Number of Gears')
axes[1, 0].set_xlabel('Number of Gears')
axes[1, 0].set_ylabel('Count')
axes[1, 0].set_yscale('log')

# Plot 4: Affordability vs Price
sns.countplot(data=data, x='price_segment', order=data['price_segment'].value_counts().sort_values(ascending=False).index, width=0.5, palette='viridis', ax=axes[1, 1])
axes[1, 1].set_title('Count of Cars by Affordability')
axes[1, 1].set_xlabel('Affordability')
axes[1, 1].set_ylabel('Count')
axes[1, 1].set_yscale('log')

# Plot 5: Fuel Type
sns.countplot(data=data, x='fuel_type', palette='viridis', order=data['fuel_type'].value_counts().sort_values(ascending=False).index, width=0.5, ax=axes[2, 0])
axes[2, 0].set_title('Count of Cars by Fuel Type')
axes[2, 0].set_xlabel('Fuel Type')
axes[2, 0].set_ylabel('Count')
axes[2, 0].set_yscale('log')

# Plot 6: Engine Type
sns.countplot(data=car_no_unspecified, x='cylinder_configuration', palette='viridis', order=car_no_unspecified['cylinder_configuration'].value_counts().sort_values(ascending=False).index, width=0.5, ax=axes[2, 1])
axes[2, 1].set_title('Count of Cars by Engine Type')
axes[2, 1].set_xlabel('Engine Type')
axes[2, 1].set_ylabel('Count')
axes[2, 1].set_yscale('log')

# Adjust layout
plt.tight_layout()
plt.show()

"""### 9. **Violin Plots**

This code generates a Violin Plot to visualize the distribution of ex-showroom prices for the top 5 car makes based on average prices.
"""

# Get the top 5 car makes based on average ex-showroom price
top_5_makes = data.groupby('make')['ex-showroom_price_inr'].mean().sort_values(ascending=False).head(5).index

# Filter the dataset for the top 5 makes
top_5_car_makes_data = data[data['make'].isin(top_5_makes)]

# Create a Violin Plot with y-axis limit
plt.figure(figsize=(15, 5))
sns.violinplot(data=top_5_car_makes_data, x='make', y='ex-showroom_price_inr', palette='viridis')
plt.title('Violin Plot of Ex-showroom Prices for Top 5 Car Makes')
plt.xlabel('Car Make')
plt.ylabel('Ex-showroom Price (INR)')
plt.show()

"""### 10. **Stacked Bar Charts**

We sort the fuel types in descending order and create a stacked bar chart illustrating the distribution of price segments across different fuel types. The bars are sorted in decreasing order based on their total count.
"""

# Sort fuel types in descending order
sorted_fuel_types = sorted(data['fuel_type'].unique(), reverse=True)

# Create a stacked bar chart for Price Segment vs Fuel Type using Plotly
fig = px.histogram(data, x='fuel_type', color='price_segment', barmode='stack',
                   category_orders={'fuel_type': sorted_fuel_types},
                   labels={'fuel_type': 'Fuel Type', 'price_segment': 'Price Segment'},
                   title='Price Segment Distribution by Fuel Type')


fig.update_layout(xaxis_title='Fuel Type', yaxis_title='Count (log scale)', legend_title='Price Segment', yaxis_type="log")
# Sort bars in decreasing order
fig.update_xaxes(categoryorder='total descending')

fig.show()

"""We filter the dataset for desired body types and create a stacked bar chart to represent the distribution of car makes within these body types. The chart provides insights into the variety of car makes present in the specified body types."""

# Filter the dataset for desired body types
filtered_car = data[data['body_type'].isin(['Coupe', 'Crossover', 'Hatchback', 'MPV', 'MUV', 'Pick-up', 'Sedan', 'Sports', 'SUV'])]

# Create a stacked bar chart for Make vs Desired Body Types using Plotly
fig = px.histogram(filtered_car, x='make', color='body_type', barmode='stack',
                   category_orders={'make': sorted(filtered_car['make'].unique(), reverse=True)},
                   labels={'make': 'Make', 'body_type': 'Body Type'},
                   title='Make Distribution by Desired Body Types')
fig.update_layout(xaxis_title='Make', yaxis_title='Count', legend_title='Body Type')
fig.update_xaxes(tickangle=45, tickmode='array', tickvals=filtered_car['make'].unique())
fig.show()

"""Here, we filter out 'unspecified' values from the 'cylinder_configuration' column and create a stacked bar chart. The chart depicts the distribution of fuel types across different cylinder configurations, providing insights into the variety of engines in the dataset."""

# Filter out 'unspecified' values from cylinder_configuration
filtered_car = data[data['cylinder_configuration'] != 'unspecified']

# Sort fuel types in descending order
sorted_fuel_types = sorted(filtered_car['fuel_type'].unique(), reverse=True)

# Create a stacked bar chart for Fuel Type vs Cylinder using Plotly
fig = px.histogram(filtered_car, x='fuel_type', color='cylinder_configuration', barmode='stack',
                   category_orders={'fuel_type': sorted_fuel_types},
                   labels={'fuel_type': 'Fuel Type', 'cylinder_configuration': 'Cylinder Configuration'},
                   title='Fuel Type Distribution by Cylinder Configuration')


fig.update_layout(xaxis_title='Fuel Type', yaxis_title='Count (log scale)', legend_title='Cylinder Configuration', yaxis_type="log")
# Sort bars in decreasing order
fig.update_xaxes(categoryorder='total descending')

fig.show()

# Drop 'feature_bins' and 'log_price' columns
car = data.drop(['feature_bins'], axis=1)
car









